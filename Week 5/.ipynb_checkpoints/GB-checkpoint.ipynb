{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.0190           12.53s\n",
      "         2           0.9192           12.28s\n",
      "         3           0.8272           10.56s\n",
      "         4           0.7834            9.55s\n",
      "         5           0.7109            9.13s\n",
      "         6           0.6368            9.60s\n",
      "         7           0.5797            9.62s\n",
      "         8           0.5610            8.95s\n",
      "         9           0.5185            8.81s\n",
      "        10           0.4984            8.36s\n",
      "        20           0.1999            7.78s\n",
      "        30           0.1313            6.70s\n",
      "        40           0.0790            6.47s\n",
      "        50           0.0511            6.06s\n",
      "        60           0.0352            5.70s\n",
      "        70           0.0245            5.25s\n",
      "        80           0.0162            4.98s\n",
      "        90           0.0114            4.63s\n",
      "       100           0.0077            4.36s\n",
      "       200           0.0004            1.26s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/svetlana/anaconda2/lib/python2.7/site-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.1255           11.89s\n",
      "         2           1.0035           11.45s\n",
      "         3           0.9386           11.14s\n",
      "         4           0.8844           10.05s\n",
      "         5           0.8381            9.64s\n",
      "         6           0.7995            9.22s\n",
      "         7           0.7559            9.09s\n",
      "         8           0.7205            9.07s\n",
      "         9           0.6958            8.75s\n",
      "        10           0.6725            8.51s\n",
      "        20           0.4672            7.60s\n",
      "        30           0.3179            7.59s\n",
      "        40           0.2274            7.57s\n",
      "        50           0.1774            6.97s\n",
      "        60           0.1394            6.85s\n",
      "        70           0.1050            6.66s\n",
      "        80           0.0805            6.21s\n",
      "        90           0.0650            5.80s\n",
      "       100           0.0511            5.41s\n",
      "       200           0.0058            1.60s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2095           10.96s\n",
      "         2           1.1006           10.89s\n",
      "         3           1.0240           10.83s\n",
      "         4           0.9729           10.97s\n",
      "         5           0.9387            9.91s\n",
      "         6           0.8948           10.29s\n",
      "         7           0.8621           10.18s\n",
      "         8           0.8360            9.63s\n",
      "         9           0.8171            9.18s\n",
      "        10           0.7883            9.03s\n",
      "        20           0.6164            7.81s\n",
      "        30           0.4933            7.09s\n",
      "        40           0.4248            6.40s\n",
      "        50           0.3345            6.22s\n",
      "        60           0.2760            5.85s\n",
      "        70           0.2263            5.56s\n",
      "        80           0.1971            5.14s\n",
      "        90           0.1693            4.78s\n",
      "       100           0.1388            4.56s\n",
      "       200           0.0294            1.51s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.2613           11.01s\n",
      "         2           1.1715           11.23s\n",
      "         3           1.1009           11.04s\n",
      "         4           1.0529           10.90s\n",
      "         5           1.0130           10.99s\n",
      "         6           0.9740           10.95s\n",
      "         7           0.9475           10.19s\n",
      "         8           0.9197           10.21s\n",
      "         9           0.8979            9.78s\n",
      "        10           0.8730            9.83s\n",
      "        20           0.7207            7.93s\n",
      "        30           0.6055            7.16s\n",
      "        40           0.5244            6.63s\n",
      "        50           0.4501            6.19s\n",
      "        60           0.3908            5.78s\n",
      "        70           0.3372            5.46s\n",
      "        80           0.3009            5.14s\n",
      "        90           0.2603            4.87s\n",
      "       100           0.2327            4.52s\n",
      "       200           0.0835            1.45s\n",
      "      Iter       Train Loss   Remaining Time \n",
      "         1           1.3199           14.20s\n",
      "         2           1.2645           13.93s\n",
      "         3           1.2170           13.18s\n",
      "         4           1.1775           12.77s\n",
      "         5           1.1404           12.51s\n",
      "         6           1.1106           12.26s\n",
      "         7           1.0844           12.14s\n",
      "         8           1.0617           12.01s\n",
      "         9           1.0411           11.94s\n",
      "        10           1.0223           11.86s\n",
      "        20           0.8864           10.51s\n",
      "        30           0.7844            9.21s\n",
      "        40           0.7176            8.13s\n",
      "        50           0.6590            7.32s\n",
      "        60           0.6120            6.68s\n",
      "        70           0.5599            6.27s\n",
      "        80           0.5242            5.77s\n",
      "        90           0.4829            5.39s\n",
      "       100           0.4473            5.00s\n",
      "       200           0.2379            1.59s\n"
     ]
    }
   ],
   "source": [
    "fname = 'gbm-data.csv'\n",
    "def download_data():\n",
    "    import os.path\n",
    "    if os.path.isfile(fname):\n",
    "        import hashlib\n",
    "        hash = hashlib.md5(open(fname, 'rb').read()).hexdigest()\n",
    "        if hash == '675c7a691add0c328b8b27db003a96aa':\n",
    "            return\n",
    "    import urllib\n",
    "    urllib.urlretrieve('https://d3c33hcgiwev3.cloudfront.net/_75fb7a1b6f3431b6217cdbcba2fd30b9_gbm-data.csv?Expires=1456790400&Signature=QVeBlc-wGKB1TjJJg0ciUwE-fifxMGUjrKC-4~Ew6oZOX3MFF2NBftJdLgY16fnxaWE3jWzZkXD1v5vWqatp1nMgGAOVzgZVPUt9Wqg5G-Y~C5Hc87NJEG2bVuIXj6zBiB9X2p4EbyW~wRXnc7yNWQdFihOohVwIL4bdgdPRYck_&Key-Pair-Id=APKAJLTNE6QMUY6HBC5A', fname)\n",
    "\n",
    "download_data()\n",
    "\n",
    "from pandas import read_csv\n",
    "data = read_csv(fname)\n",
    "\n",
    "X = data.iloc[:,1:]\n",
    "y = data.iloc[:,0]\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.8, random_state=241)\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "import numpy as np, os\n",
    "if not os.path.exists('plots'):\n",
    "    os.makedirs('plots')\n",
    "\n",
    "def plot(train_loss, test_loss, fname):\n",
    "    import matplotlib\n",
    "    matplotlib.use('Agg')\n",
    "    import matplotlib.pyplot as plt\n",
    "    # %matplotlib inline\n",
    "    plt.figure()\n",
    "    plt.plot(test_loss, 'r', linewidth=2)\n",
    "    plt.plot(train_loss, 'g', linewidth=2)\n",
    "    plt.legend(['test', 'train'])\n",
    "    plt.savefig(fname)\n",
    "\n",
    "min_losses = {}\n",
    "for index, learning_rate in enumerate([1, 0.5, 0.3, 0.2, 0.1], start=1):\n",
    "    clf = GradientBoostingClassifier(n_estimators=250, learning_rate=learning_rate, verbose=True, random_state=241)\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_pred_iters = clf.staged_predict_proba(X_train)\n",
    "    test_pred_iters = clf.staged_predict_proba(X_test)\n",
    "    train_loss = [ log_loss(y_train, pred) for pred in train_pred_iters]\n",
    "    test_loss = [ log_loss(y_test, pred) for pred in test_pred_iters]\n",
    "    best_iter = np.argmin(test_loss)\n",
    "    min_losses[learning_rate] = (test_loss[best_iter], best_iter)\n",
    "    plot(train_loss, test_loss, 'plots/%d_%.1f.png' % (index, learning_rate))\n",
    "\n",
    "# based on plots view\n",
    "with open('q2.txt', 'w') as output:\n",
    "    output.write('overfitting')\n",
    "\n",
    "with open('q3.txt', 'w') as output:\n",
    "    output.write('%.2f %d' % min_losses[0.2])\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rf = RandomForestClassifier(n_estimators=min_losses[0.2][1], random_state=241)\n",
    "rf.fit(X_train, y_train)\n",
    "rf_pred = rf.predict_proba(X_test)[:, 1]\n",
    "rf_score = log_loss(y_test, rf_pred)\n",
    "\n",
    "with open('q4.txt', 'w') as output:\n",
    "    output.write('%.2f' % (rf_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
